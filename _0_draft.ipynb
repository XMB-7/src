{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:36:52.684659Z",
     "start_time": "2021-11-01T02:36:52.267053Z"
    },
    "code_folding": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1046,
     "status": "ok",
     "timestamp": 1635614706052,
     "user": {
      "displayName": "Xiaoming Bai",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14301546434876474122"
     },
     "user_tz": -480
    },
    "id": "AWPFoawyE4lU",
    "outputId": "b243d899-7862-42e6-d675-54f1b0108975"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\n\\nf = os.popen(\"nvidia-smi\")\\nprint(f.read())\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "\n",
    "f = os.popen(\"nvidia-smi\")\n",
    "print(f.read())\n",
    "\n",
    "'''\n",
    "\n",
    "# 亦可选择直接执行!nvidia-smi\n",
    "# 但这会局限于ipython\n",
    "\n",
    "# 不要使用os.system(\"!nvidia-smi\")\n",
    "# 语句虽能正常执行 但根本看不到相应显卡信息 因为一执行完shell就自动关闭了\n",
    "#\n",
    "# os.popen()则会执行系统命令然后返回文件对象\n",
    "# popen = process open\n",
    "#\n",
    "# 但其实这俩函数都已经被废弃了 (并非已然无法使用 但建议是别再用了)\n",
    "# 使用subprocess模块 会有更好的可移植性以及安全性\n",
    "# 这是一个内建模块 无需进行额外安装 \n",
    "# 它通过子进程执行外部指令 并由input/output/error管道 获取子进程的执行返回信息\n",
    "#\n",
    "# os模块之中 被废弃或者说被上位替代的函数还有很多\n",
    "# 比如os.walk()之于os.scandir() 以及os.getenv()还有os.putenv()之于os.environ (注意这是字典)\n",
    "# https://docs.python.org/zh-cn/3/library/os.html ⁉️\n",
    "\n",
    "# 最后完全可以缀上个空语句 从而避免打印结果 \n",
    "# 但感觉不美观 这也是多行注释的弊端 仍不确定是否使用这种注释\n",
    "# 这个显示出的结果具体是怎么显示的 有的就能用空语句消掉 但有的就不能\n",
    "# 感觉是机制不一样 可能有的就是print 但有的是__setattr__ ⁉️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar  2 05:23:49 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-PCI...  On   | 00000000:01:00.0 Off |                   On |\n",
      "| N/A   39C    P0    35W / 250W |    386MiB / 40536MiB |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n",
      "|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n",
      "|                  |                      |        ECC|                       |\n",
      "|==================+======================+===========+=======================|\n",
      "|  0    1   0   0  |    376MiB / 20096MiB | 42      0 |  3   0    2    0    0 |\n",
      "|                  |      4MiB / 32767MiB |           |                       |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "|  0    2   0   1  |     10MiB / 20096MiB | 42      0 |  3   0    2    0    0 |\n",
      "|                  |      0MiB / 32767MiB |           |                       |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0    1    0      12573      C   ./runner12                        179MiB |\n",
      "|    0    1    0      52796      C   ./runner12                        179MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.call(\"nvidia-smi\", shell=True)\n",
    "\n",
    "# 参考Python文档 继续学习相关用法 还是挺复杂的\n",
    "# https://docs.python.org/zh-cn/3/library/subprocess.html ⁉️\n",
    "#\n",
    "# 此外还有一些其它相关信息\n",
    "# https://blog.csdn.net/qq_27825451/article/details/102909772 ⁉️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GPU on Linux g4 (1 x Tesla A100) is set in multi-instance mode,\n",
    "which can be partitioned into separate instances.\n",
    "\n",
    "To identify and choose one instance to use:\n",
    "1) nvidia-smi -L\n",
    "2) if using bash: export CUDA_VISIBLE_DEVICES=MIG-xxx-xxx-xxx-xxx-xxx\n",
    "   if using tcsh: setenv CUDA_VISIBLE_DEVICES MIG-xxx-xxx-xxx-xxx-xxx\n",
    "3) Then run your code as normal.\n",
    "\n",
    "Device 0: MIG-57ae2138-d2c4-5c06-a29a-df60c612e14e\n",
    "Device 1: MIG-26238f5d-6826-5e90-a3f7-71eae092d7ba\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "import subprocess\n",
    "\n",
    "subprocess.call(\"nvidia-smi -L\", shell=True)\n",
    "# 不必再执行了 序号上面都记录了 应该不会变动\n",
    "\n",
    "'''\n",
    "\n",
    "# 如果采用多行注释 注意对代码要用单引号 对文本要用双引号\n",
    "# 这是个人习惯 双引号表语义\n",
    "\n",
    "\n",
    "subprocess.call(\"export CUDA_VISIBLE_DEVICES=MIG-57ae2138-d2c4-5c06-a29a-df60c612e14e\",\n",
    "                shell=True)\n",
    "\n",
    "# ---\n",
    "# subprocess.call(\"export CUDA_VISIBLE_DEVICES=MIG-26238f5d-6826-5e90-a3f7-71eae092d7ba\",\n",
    "#                 shell=True)\n",
    "# ---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "在学校的服务器上 我只被分配了32GB 这点存储空间根本就不够用\n",
    "所以说雷达数据的下载 以及后续的绘图与保存 全都要去colab上面完成\n",
    "也幸好colab能挂载google drive 处理好的图片可以即时存入 否则断线清空还是个大麻烦\n",
    "\n",
    "图片处理完毕 还要将之从云盘下载到本机 再手动传入学校服务器\n",
    "在学校服务器上直接挂载谷歌云盘进而完成图片下载似乎是做不到的\n",
    "除了colab以及kaggle能用api 其它的服务器貌似都不可以\n",
    "而在服务器上选择安装谷歌云盘应用 对于远程连接又非常不友好 传图形界面实在是太卡\n",
    "所以暂且只能这样 好在训练数据总是相对不变 只要上传一次就一劳永逸了\n",
    "\n",
    "后来发现vscode有个插件 google drive for vscode\n",
    "但是测试发现 只能下载单个文件 甚至不能多选下载 所以还是挺鸡肋的\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "这是训练数据 至于代码部分 则会使用git并发布到github进行备份\n",
    "注意设置.gitignore 要忽略掉.ipynb_checkpoint以及__pychache__ ⁉️\n",
    "\n",
    "在colab里 用命令行指令克隆代码仓库 即可获取最新代码\n",
    "最简单方式是!git clone <url>\n",
    "这步集成不进这一笔记本里 只能自己手动操作\n",
    "\n",
    "其实完全能在colab里面自由使用git 包括推送等等\n",
    "https://www.geeksforgeeks.org/how-to-install-and-use-git-in-google-colab\n",
    "\n",
    "若只需要去打开仓库里的笔记本 那么还有更简便的操作方法\n",
    "https://blog.csdn.net/yhblog/article/details/121534768\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 在ipython里 执行命令行指令 需要前缀叹号 (亦可再加空格)\n",
    "# 但是执行ipython魔法函数 百分号后务必不能追加空格 \n",
    "# 比如%pwd正常 但是% pwd报错 ⁉️\n",
    "# \n",
    "# 注意 若要继承执行结果 必须使用魔法函数\n",
    "# 典型案例就是cd 必须要用%cd而非!cd才有效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:37:52.953046Z",
     "start_time": "2021-11-01T02:37:52.949964Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "数据处理往往要和训练分开 但这是all-in-one笔记本 所以配置文件将会包含所有相关参数\n",
    "而这里特意把它们俩单独拎出来 则是为了修改方便 省去打开配置文件这一步骤\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "skip_download = True\n",
    "skip_plot = True\n",
    "\n",
    "import _1_arguments\n",
    "# 注意模块名不能以数字开头 \n",
    "# 为了实现排序只能如此起名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:37:55.293064Z",
     "start_time": "2021-11-01T02:37:55.280694Z"
    },
    "code_folding": [],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "executionInfo": {
     "elapsed": 1013,
     "status": "ok",
     "timestamp": 1635611539146,
     "user": {
      "displayName": "Xiaoming Bai",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14301546434876474122"
     },
     "user_tz": -480
    },
    "id": "KsL1wYcdE4lf",
    "outputId": "d3d80c55-d5c5-4043-e96c-11f5829fd97a"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "这是一段废弃代码 用于读取云盘中的配置文件\n",
    "之所以还保留 主要因为上面还有学习笔记\n",
    "\n",
    "之前的方案是 代码存进谷歌云盘 进入colab之后 通过挂载谷歌云盘访问脚本\n",
    "但由于代码修改不直接发生在云盘里 所以每次更新都要上传一遍\n",
    "而我经常遗忘这点 经常是在旧代码上继续修改 非常折磨 所以最终还是学了git\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "import os\n",
    "\n",
    "if use_colab:\n",
    "    from google.colab import drive\n",
    "    # 如前所述 这个api只对colab或者kaggle好使\n",
    "    # 其它的服务器根本挂载不了 即便已安装了google\n",
    "    \n",
    "    mount_dir = \"/content/drive\"\n",
    "    # colab默认挂载路径 \n",
    "    # 并不建议更改 这样更加便于移植\n",
    "    drive.mount(mount_dir)\n",
    "    # 注意挂载之后并未进入挂载路径 \n",
    "    # 因为现在只需要读 无需往云盘里写文件 \n",
    "\n",
    "    rel_path = \"MyDrive/MyProjects/Weather Nowcasting/XMB-7/arguments.py\"\n",
    "    # 配置文件在云盘中所在路径\n",
    "    file_path = os.path.join(mount_dir, rel_path)\n",
    "\n",
    "    %run $file_path\n",
    "    # 不能直接使用格式化字符串\n",
    "    # 顺便一提 这里甚至不能在句尾加注释\n",
    "    # 这是bash样式 并非python语法 故而不能混在一行\n",
    "    # 其实这也挺奇怪的 明明ipython 魔法函数的样式却偏偏是命令行 ⁉️\n",
    "\n",
    "else:\n",
    "# 当本机运行时\n",
    "    import _1_arguments\n",
    "\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lQ-finPuE4lh"
   },
   "source": [
    "# Data Download"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5od_pdQRE4lj"
   },
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:37:11.368075Z",
     "start_time": "2021-10-30T01:37:11.358101Z"
    },
    "code_folding": [
     0
    ],
    "id": "3BePtgN9E4lm"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "手动查找强沉降的发生日期 并为每天仅挑出一个强沉降的长持续时段\n",
    "记录年月日期以及起止时刻 以便稍后统一下载相对应的数据文件\n",
    "格式不妨选为%Y%m%d_%H%M%S 比如20201012_080102\n",
    "起止时刻直接取整 向上和向下取整到小时\n",
    "稍微囊括进来一些沉降的形成与消弭 完全不碍事的 甚至还是很有必要\n",
    "选出的时段内包含少量晴天也是没问题的 稍后还会进行过滤 以去除沉降强度过低的部分序列\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 要注意这个时段只表示下载范围 比如(20201012_080102, 20201012_200102)\n",
    "# 只是表明需要下载时段之中所有数据 并不代表起止时刻一定会有雷达数据\n",
    "\n",
    "# 目前是按天选择连续的沉降时段 直接杜绝跨天现象\n",
    "# 如此一来 在构建序列数据集之时 就不必费力去确保序列内部各图像之间的时间连续性了\n",
    "# 此种做法比较偷懒 数据利用率是比较低的\n",
    "# 但由于气象数据过往记录足够多 选择余地很大 所以本身也没什么坏处\n",
    "#\n",
    "# 但我总感觉应该按一次完整的沉降来进行建模 ⁉️\n",
    "\n",
    "# 找组里要一下筛选强沉降日期的代码 ⁉️\n",
    "\n",
    "# Cuomo还调整了强沉降发生当天的强沉降序列和弱沉降序列的数目比例 以使二者大致相等\n",
    "# 但感觉不需要 机器理应学习沉降开始和消弭的过程\n",
    "# 但再一想 如果每天的数据都只有很少的一部分是强沉降序列那也不太好 所以还是应该稍微手动调整一下 ⁉️\n",
    "\n",
    "\"\"\"\n",
    "等到具体下载之时 以日期为文件夹名 将来自不同日期的数据存入不同的文件夹之中\n",
    "而且稍后处理雷达数据文件以及最终保存雷达数据图像也都是要这样\n",
    "总之对数据要按天进行处理 \n",
    "\n",
    "顺便一提 如前所述建议使用colab绘制以及存储图像 直接同步进谷歌云盘\n",
    "这样比较节省个人硬件资源 毕竟待下载的雷达文件还是非常多的\n",
    "colab虽然有在线时长的限制 但我已经考虑到了断线续接 如果没跑完就中断了 直接重跑代码即可\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3PC5lNE5E4l1"
   },
   "source": [
    "### Preparatory Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_download:\n",
    "    \n",
    "    import subprocess\n",
    "\n",
    "    from datetime import datetime\n",
    "    from datetime import timedelta\n",
    "    \n",
    "    try: from IPython.display import clear_output\n",
    "    # 即时清除当前单元格的输出 \n",
    "    # 通过设置唯一参数wait 指定是否在有新输出时清除旧输出\n",
    "    # 往往用于循环 for i in range(10): print(i); clear_output(True)\n",
    "    # 或是特意清除之前所有输出\n",
    "    #\n",
    "    # 如果用的不是ipython 那么就要根据操作系统调用os.system(‘cls’)或者os.system(‘clear’)\n",
    "    # 注意它们对ipython根本没有用 因为不是终端\n",
    "    except: pass\n",
    "\n",
    "    try: import nexradaws\n",
    "    except ImportError: \n",
    "        subprocess.call(\"pip install nexradaws\", shell=True)\n",
    "        import nexradaws\n",
    "\n",
    "    try: clear_output(True)\n",
    "    # 适配各种开发环境 因为用的可能不是ipython\n",
    "    except: pass\n",
    "    # 导入nexradaws之后 会打印出对该包的引用信息 重复导入才可消去\n",
    "    # 故而直接clear_output()将之清空\n",
    "    # 但后来发现不再弹出了 不知何故 或是解释器版本更新了 ⁉️"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ImISFUntQNpR"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:55.698321Z",
     "start_time": "2021-10-30T01:40:55.692947Z"
    },
    "code_folding": [
     0
    ],
    "id": "iFtBXHA8QNpT",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def get_clerical_errors_in_precip_periods():\n",
    "    \"\"\"\n",
    "    Discription:\n",
    "    ---\n",
    "    Check a simple type of potential errors \n",
    "    in the recorded precipitation period list of tuples\n",
    "    for which the end time point is earlier than the start.\n",
    "    Return the corresponding precipitation periods in a list.\n",
    "    If not find any, return an empty list.\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    error: list of tuples,\n",
    "    a list of tuples each indicating where a clerical error comes from.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # 检测某天沉降时段终止时刻是否早于起始时刻\n",
    "    # 只为避免这样一种低级失误 并不能保证这些沉降时段都是适合训练的\n",
    "    \n",
    "    errors_found = []\n",
    "    for month in args.precip_periods.keys():\n",
    "        for precip_period in args.precip_periods[month]:\n",
    "            if precip_period[0] >= precip_period[1]:\n",
    "            # 这里还有优化空间 看看该怎么把0/1改成start/end 毕竟索引没有语义 ⁉️\n",
    "                errors_found.append(precip_period)\n",
    "                \n",
    "    return errors_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:55.721059Z",
     "start_time": "2021-10-30T01:40:55.700222Z"
    },
    "code_folding": [
     0
    ],
    "id": "lpdvh0zlQNpW"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mJupyter Notebook 服务器未能及时启动. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "def print_errors(errors_found):\n",
    "    \"\"\"\n",
    "    Discription:\n",
    "    Print out any clerical errors found in the records of precipitation periods.\n",
    "    \n",
    "\n",
    "    Parameters:\n",
    "    errors_found: list of tuples,\n",
    "    clerical errors detected by calling get_typos_in_precip_periods().\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if len(errors_found):\n",
    "        print(\"Clerical errors in the records of precipitation periods,\")\n",
    "        print(\"for each tuple the end time point is earlier than the start:\")\n",
    "        print()\n",
    "        # 使用print语句 需要考虑与后续潜在的print语句是否进行额外分隔\n",
    "        # print默认参数自带换行 而这里是额外插入一个空行\n",
    "        print(\"---\")\n",
    "        print()\n",
    "        # 有无更优雅的方式 甚至换个函数 比如log模块 ⁉️\n",
    "\n",
    "        for error in errors_found:\n",
    "            print(error)\n",
    "            # 每个元组独占一行 这样显示效果更好\n",
    "            # 别直接print(errors_found)\n",
    "        print()\n",
    "        print(\"---\")\n",
    "        print()\n",
    "        print(\"Please re-run the code after error corrections.\")\n",
    "        print()\n",
    "        # 对于函数或方法的最后一个print 尤其需要关注是否应该对此进行额外分隔\n",
    "        # 因为再下一个print语句已在其外 \n",
    "        # 若不提前考虑 彼时难免就要来回跳转反复查看最终才能决定 比较麻烦\n",
    "        # 所以通常都会无脑选择追加一个空行 若不合适取消就好 (函数或方法内外的print语句连贯没有空行)\n",
    "        #\n",
    "        # 但弊端是这个追加出的空行会被提前打印出来 而不会临执行下一个print语句时才被打印出来\n",
    "        #\n",
    "        # 这里的if和else分支里 各自最后打印空行 可以换成在分支外最后追加\n",
    "        # 但不建议这样 降低了可读性 追加分隔就该捆绑print 最好不要出现空间分离现象\n",
    "        \n",
    "    else: \n",
    "        print(\"No clerical errors found in the records of precipitation periods.\")\n",
    "        print(\"Go ahead to download radar data files.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:55.742496Z",
     "start_time": "2021-10-30T01:40:55.722992Z"
    },
    "code_folding": [
     0
    ],
    "id": "P7z7pDxWQNpY",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def download_nexrad_sigmet_files():\n",
    "# 下载失败提示 命令行解压缩 嵌套中的长字符串打印 ❓\n",
    "    \"\"\"\n",
    "    Discription:\n",
    "    Download the selected nexrad sigmet files,\n",
    "    and return the number of successful downloads, \n",
    "    along with a list of failed files.\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    num_success: int,\n",
    "    the total number of files that have been successfully downloaded,\n",
    "    not only in current runtime, but across multiple runtimes,\n",
    "    assuming that interruptions may occur so requiring several runtimes \n",
    "    to complete the whole downloading process.\n",
    "\n",
    "    files_failed: list,\n",
    "    a list of all file names failed to download so far.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    num_success = 0\n",
    "    files_failed = []\n",
    "    \n",
    "    for month in args.precip_periods.keys():\n",
    "        for period in args.precip_periods[month]:\n",
    "            # \n",
    "            # 准备下载列表\n",
    "            # \n",
    "            start = datetime.strptime(period[0], '%Y%m%d_%H%M%S')\n",
    "            end = datetime.strptime(period[1], '%Y%m%d_%H%M%S')\n",
    "            # 若想使用nexradaws 需把时间从字符串转成datetime对象\n",
    "            connection = nexradaws.NexradAwsInterface()\n",
    "            scans = connection.get_avail_scans_in_range(\n",
    "                start, end, args.radar_id\n",
    "            )\n",
    "            scans = [scan for scan in scans if '_MDM' not in scan.filename]\n",
    "            # 不必下载以_MDM结尾的文件 将之从待下载列表中移除\n",
    "            \n",
    "            save_dir = f'{args.files_rootdir}/{period[0][0: 7]}'\n",
    "            # 最后是在提取数据所属日期 如前所述以日期为文件夹名\n",
    "            #\n",
    "            # \\在代码之中表示软换行 也包括在字符串中 别忘了字符串本身就是代码 \n",
    "            # 所以这里要么直接使用原始字符串 要么用/或\\\\来替代\\ (\\\\是\\的转义字符) \n",
    "            # 更加推荐使用/ 因为只有它才便于移植 其余那俩 一是python语法 一是windows语法\n",
    "\n",
    "            # \n",
    "            # 考虑断线续接问题\n",
    "            # \n",
    "            if os.path.exists(save_dir) and \\\n",
    "            len(scans) == len(os.listdir(save_dir)):\n",
    "            # 如果下载路径已被创建 并且其中文件数目准确无误 则跳过相应部分的下载\n",
    "            #\n",
    "            # 软换行后 规范似乎是加一个缩进 但这容易让人误以为子代码块\n",
    "                num_success += len(scans)\n",
    "                \n",
    "            else:\n",
    "            # 若下载路径尚未被创建 或其中文件数目对不上\n",
    "            # 则说明下载曾发生中断 此时就要重新下载当天所有数据 \n",
    "                print(f\"Downloading files from {period[0][0: 7]}...\")\n",
    "                files = connection.download(scans, save_dir)\n",
    "                print()\n",
    "                # 这个批量下载是自带多个连续的print语句的\n",
    "                # 所以在下完某天的数据之后 最好手动补一个空行 从而额外分隔与下一天的输出\n",
    "                \n",
    "                #\n",
    "                # 下载完毕之后整理成功与失败的信息\n",
    "                #\n",
    "                num_success += files.success_count\n",
    "                if files.failed_count != 0:\n",
    "                    files_failed += [file.filename for file in files.failed]\n",
    "                    # ? 这里可能有点问题 或许这个file就已经是文件名了\n",
    "                    # ? 然而由于还没遇到过下载失败的情况 所以暂时无法进行验证\n",
    "                \n",
    "                for file in os.listdir(save_dir):\n",
    "                # 如果下载到了压缩文件数据 则要进行解压\n",
    "                    if '.gz' in file:\n",
    "                        os.system('gunzip -f ' + os.path.join(save_dir, file))\n",
    "                        # ? 亲自试了一下解压rar文件 没能成功 不知道为什么\n",
    "                        # ? 是不是需要在gunzip前面加!啊\n",
    "                        # ? 我好像发现把anaconda直接加入环境变量的问题了\n",
    "                        # ? 所有linux命令好像都失效了 !pwd必须得pwd 其实之前pip就能执行就已经有苗头了 只不过当时没注意\n",
    "                        # ? 似乎又发现pwd并非命令行指令 不知道咋回事\n",
    "                        # ? 但我换了台电脑试了一下 发现上述理解又不对\n",
    "                        # ? 还是找时间搜一下anaconda加入环境变量有什么弊端吧\n",
    "                        # ? gzip是压缩 gunzip是解压 自己试试\n",
    "                        # ? 而且这里还有问题 解压之后用不用把压缩包删掉啊 不删文件数就多了 影响程序执行 \n",
    "                        # ? 目前尚未遇到压缩文件 所以暂时不用关心\n",
    "                        # ? https://blog.csdn.net/home_zhang/article/details/7977491?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3.no_search_link\n",
    "                        # ? 或许要等学完linux才行 发现好多zip包 zip m2-gzip等等 都不知道安装哪个\n",
    "                        # ? .gz就是linux压缩包 随便上github下一个源码包都有.gz的\n",
    "                        \n",
    "    print(f\"{num_success} files have been downloaded in total.\", end=\"\\r\")\n",
    "    print()\n",
    "    \n",
    "    if len(files_failed):\n",
    "        print(f\"{len(files_failed)} files failed to be downloaded and displayed below.\")\n",
    "        print(\"---\")\n",
    "        for file in files_failed:\n",
    "            print(file)\n",
    "        print(\"---\")\n",
    "        print(\"Please re-run to see if those failed files would be successfully\",\n",
    "              \"downloaded in the next runtime.\",\n",
    "              sep=\" \")\n",
    "        print(\"If not, plese download them by hand and put it into the proper folder\",\n",
    "              \"or just delete the correspoinding precipitation period records\",\n",
    "              \"to simply skip downloading them.\",\n",
    "              sep=\" \")\n",
    "        print(\"Otherwise the upcoming dataset construction process\",\n",
    "              \"would be severely influenced.\",\n",
    "              sep=\" \")\n",
    "        print()\n",
    "        \n",
    "    # ? 在嵌套的结构中打印长句 如果使用换行符\\ 就导致下一行会顶行开始 丧失嵌套结构 非常难看\n",
    "    # ? 如果人为添加缩进 那么最后还得用字符串的strip方法给调整回来 非常繁琐 所以暂时不知道有没有什么好方法\n",
    "    \n",
    "    return num_success, files_failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLKTQ9ecQNpa"
   },
   "source": [
    "# Extract Image Arrays and Save Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "65FOKagKQNpc"
   },
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:55.760064Z",
     "start_time": "2021-10-30T01:40:55.744440Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "id": "GTuNAl4sQNpc"
   },
   "outputs": [],
   "source": [
    "# 读取雷达数据 转换图像数组 检测沉降强度 绘图并且存储 \n",
    "# 注意将沉降信息与时间信息同时存入文件名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:55.780204Z",
     "start_time": "2021-10-30T01:40:55.761913Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "id": "kJL7naHZQNpf"
   },
   "outputs": [],
   "source": [
    "# 直接存储图像会比存储图像数组节约两三倍的存储空间 # ? 原因\n",
    "# 因此选择放弃使用后者转而使用前者\n",
    "# ? 暂时不知为何 虽然把前者读进来明明就跟后者完全一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:55.799669Z",
     "start_time": "2021-10-30T01:40:55.781951Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "id": "4-kmpKyNQNph"
   },
   "outputs": [],
   "source": [
    "# 手动检查已保存的图片 # ? 要筛选日期的代码\n",
    "# 若某天里一个强沉降的图像都没有 那就删去该天的所有数据 完了新找一天下载并且检查新的数据\n",
    "# ? 暂且先这样 如前所述有时间再找Kim或Jacob要一下用于筛选强沉降发生的日期的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:55.818807Z",
     "start_time": "2021-10-30T01:40:55.801353Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "id": "6YNK_WfdQNph"
   },
   "outputs": [],
   "source": [
    "# ? 如前所述 Cuomo还调整了强沉降发生当天的强沉降序列和弱沉降序列的数目比例 以使二者大致相等 \n",
    "# ? 但感觉不需要 机器理应学习沉降开始和消弭的过程\n",
    "# ? 但再一想 如果每天的数据都只有很少的一部分是强沉降序列那也不太好 所以还是应该稍微手动调整一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:55.837710Z",
     "start_time": "2021-10-30T01:40:55.820501Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "id": "Zxnautk8QNpj"
   },
   "outputs": [],
   "source": [
    "# ? 这里未来或许会进行时间插值 用pandas的内插算法把不规则的时间间隔变成均匀的 \n",
    "# ? 然而是先处理再插值还是先插值再处理呢 或许应该是前者 起码应该先把非数值的都处理掉\n",
    "# ? 这个原理是啥啊 具体有待研究Cuomo写的教学案例 而且最好专门去查下这个插值算法\n",
    "\n",
    "# !!!\n",
    "# ? 忽然发现这个其实可以作为一个标签 用来比对我的预测到底好不好 \n",
    "# ? 另外还可以从周边的雷达站那里查找相同地点不同时间的数据来进行比对\n",
    "# !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:55.856935Z",
     "start_time": "2021-10-30T01:40:55.839680Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "id": "FuAw8E4oQNpj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # ? args.grid_limits = ((0., 20000.), (-3e5, 3e5), (-3e5, 3e5))\n",
    "# # ? (x, y)范围是否过大 Cuomo用的是(-1.5e5, 1.5e5), (-1.5e5, 1.5e5)\n",
    "# # ? 再者z的范围设为(0., 20000.)是否合适 Cuomo用的是(radar.altitude['data'][0], 20000) \n",
    "# # ? 找了一个文件试了一下 radar.altitude['data']=[236.]\n",
    "# # ? 所以z的范围在我看来最标准的设法应该是(236, 236) 其余都一样 因为只有236这一高度才有数据\n",
    "# # ? 而写成(0., 20000.)或(radar.altitude['data'][0], 20000)则是为了普适 方便其它应用场合读取进来多个扫描数据\n",
    "# # ? 但事实却并非如此 暂时无法解释以下代码结果\n",
    "\n",
    "# path = r\"G:\\我的云端硬盘\\MyProjects\\Weather Nowcasting\\XMB-7\\KFWS_Sigmet\\2020-01-03\\KFWS20200103_060305_V06\"\n",
    "# radar_data = pyart.io.read(path).extract_sweeps([0])\n",
    "# grid_limits1 = ((0., 20000.), (-3e5, 3e5), (-3e5, 3e5))\n",
    "# grid_limits2 = ((0, 236), (-3e5, 3e5), (-3e5, 3e5))\n",
    "# grid_limits3 = ((236., 20000.), (-3e5, 3e5), (-3e5, 3e5))\n",
    "# temp = []\n",
    "# for i in range(3):\n",
    "#     grid = pyart.map.grid_from_radars(\n",
    "#         radar_data, fields=[args.field],\n",
    "#         grid_shape=args.grid_shape, grid_limits=eval(f\"grid_limits{i + 1}\"),\n",
    "#         weighting_function=\"BARNES2\")\n",
    "#     img_arr = grid.fields[f\"{args.field}\"][\"data\"].data[0]\n",
    "#     img_arr = np.ma.filled(img_arr, fill_value=0)\n",
    "#     img_arr = np.clip(img_arr, args.field_value_range[0], args.field_value_range[1])\n",
    "#     img_arr = np.rint(img_arr / args.field_value_range[1] * 255)                \n",
    "#     # img_arr = img_arr.astype(\"uint8\")\n",
    "#     # 特意注释掉了这句\n",
    "#     temp.append(img_arr)\n",
    "# img1 = Image.fromarray(np.uint8(temp[0]))\n",
    "# # 如果不特意将数据类型转化为np.uint8 稍后打印输出图像是显示不出来的\n",
    "# img2 = Image.fromarray(np.uint8(temp[1]))\n",
    "# img3 = Image.fromarray(np.uint8(temp[2]))\n",
    "# print((temp[0] == temp[1]).all(), (temp[0] == temp[2]).all(), (temp[1] == temp[2]).all())\n",
    "# print(temp[0].sum(), temp[1].sum(), temp[2].sum())\n",
    "# # img1, img2, img3\n",
    "# img1\n",
    "\n",
    "# # ? 离谱的是 尝试给z的范围设置不同的值 比如(0, 0), (2e4, -2e4), (236, 236)等等\n",
    "# # ? 你会看到各种违背前述认知的代码结果 典型例如(0., 20000.)和(0., 236.)相同却和(236., 20000.)不同\n",
    "# # ? 其它还有数值判断上相等但图画出来却不同的情况\n",
    "# # ? 有时间再探究 反正所有数据都取(0., 20000.) 对模型学习而言应该是没什么影响的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:55.875582Z",
     "start_time": "2021-10-30T01:40:55.858705Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "id": "ABEczmVtQNpj"
   },
   "outputs": [],
   "source": [
    "# ? args.grid_shape = (1, 128, 128)\n",
    "# ? 因为绘制的是俯视平面图 所以20000m的垂直数据直接就压成一个网格点即可?\n",
    "# ? 然后再各选用128个网格点覆盖横纵60000m的范围 从而使得每个像素代表一个网格点?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8g8fmZ59QNpl"
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mJupyter Notebook 服务器未能及时启动. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T05:57:10.222379Z",
     "start_time": "2021-10-30T05:57:10.127959Z"
    },
    "code_folding": [
     0
    ],
    "id": "28Z-oQvMQNpl",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "try: import pyart\n",
    "except ImportException:\n",
    "    os.system('pip install arm_pyart')\n",
    "    import pyart\n",
    "\n",
    "try: import cartopy\n",
    "except ImportException:\n",
    "    os.system('pip install cartopy')\n",
    "    import cartopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "try: clear_output()\n",
    "except: pass\n",
    "# 导入pyart和导入nexradaws一样 不再赘述\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# # 如果没有使用IPython 那就需要考虑忽略警告信息 至于引用信息就用重复执行来消除 \n",
    "# # 再者 执行这一语句本身其实也会弹出警告 同样需要重复执行来消除\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4xldtYaQNpl"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:55.916111Z",
     "start_time": "2021-10-30T01:40:55.897062Z"
    },
    "code_folding": [
     0
    ],
    "id": "6KwNyJ3FQNpl"
   },
   "outputs": [],
   "source": [
    "def check_if_single_img_covers_intense_precip(img_arr): # ? 去掉了阈值归一化\n",
    "    \"\"\"\n",
    "    Description\n",
    "    ---\n",
    "    This function is equavelent to what a CNN average pooling layer does: \n",
    "    convolve an image array with a kernel to see if any local region covers \n",
    "    intense precipitation content.\n",
    "    Return True if so.\n",
    "    \n",
    "    Parameters\n",
    "    ---\n",
    "    img_arr : numpy.ndarray\n",
    "        A single image 2D array of shape (height, width).\n",
    "    \n",
    "    Returns\n",
    "    ---\n",
    "    if_required : bool\n",
    "        A flag to indicate if a image array could be regarded as covering \n",
    "        intense precipitation content.\n",
    "    \"\"\"\n",
    "    img_h = img_arr.shape[0]\n",
    "    img_w = img_arr.shape[1]\n",
    "    \n",
    "    if args.kernel_size: \n",
    "        k_h = args.kernel_size.shape[0]\n",
    "        k_w = args.kernel_size.shape[1]\n",
    "    else:\n",
    "    # 若未指定卷积核的大小 则默认将待考察的局部大小设为图像整体高宽的八分之一\n",
    "        k_h = img_h // 8\n",
    "        k_w =  img_w // 8\n",
    "    \n",
    "    conv_result = np.zeros(\n",
    "        (img_h - k_h + 1, img_w - k_w + 1)\n",
    "    )\n",
    "    for i in range(conv_result.shape[0]):\n",
    "        for j in range(conv_result.shape[1]):\n",
    "            conv_result[i, j] = (img_arr[i: i + k_h, j: j + k_w]).sum()\n",
    "    conv_result /= (k_h * k_w)\n",
    "    conv_result = np.where(conv_result <= args.field_value_range[1], 0, 1)\n",
    "    \n",
    "    if conv_result.sum() >= args.thresholds[\"frame\"][1]:\n",
    "        if_required = True \n",
    "    else:\n",
    "        if_required = False\n",
    "        \n",
    "    return if_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:55.936302Z",
     "start_time": "2021-10-30T01:40:55.918025Z"
    },
    "code_folding": [
     0
    ],
    "id": "6VcKP-sBQNpl",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def get_single_image_array_with_precip_flag(radar_data): # ? grid含义 内插函数 去掉了/70*255这步\n",
    "    \"\"\"\n",
    "    Discription\n",
    "    ---\n",
    "    Extract radar data from one radar data file as a 2D array.\n",
    "    Directly treat all the values in that 2D array as image pixel values, this \n",
    "    could be done since all the values are clipped into (0, 70) which is a subset of\n",
    "    (0, 255).\n",
    "    Then make several kinds of transformations for further better plotting.\n",
    "    Also check if this image array covers intense precipitation content.\n",
    "        \n",
    "    Parameters\n",
    "    ---\n",
    "    radar_data : obj\n",
    "        An instance derived from a radar data file when read in by using PyART.\n",
    "        \n",
    "    Returns\n",
    "    ---\n",
    "    img_arr : numpy.ndarray\n",
    "        A numpy 2D array of pixel values which could be directly plotted.\n",
    "    if_required : bool\n",
    "        True for indicating this image array covers intense precipitation content.\n",
    "    \"\"\" \n",
    "    \n",
    "    grid = pyart.map.grid_from_radars(\n",
    "    # ? Cuomo将之命名为grids 就看能否理解这一变量的含义了 暂时不予关心\n",
    "        radar_data, fields=[args.field],\n",
    "        grid_shape=args.grid_shape, grid_limits=args.grid_limits,\n",
    "        weighting_function=\"BARNES2\"\n",
    "        # 内插函数\n",
    "        # ? 这个内插函数跟pandas的内插函数有啥区别 暂时不予关心\n",
    "    )\n",
    "    img_arr = grid.fields[f\"{args.field}\"][\"data\"].data[0]\n",
    "    # 去除掩藏的部分 仅仅取出雷达数据图片所对应的二维数组\n",
    "    # 最后这个[0]是从(1, 256, 256)中提取(256, 256)\n",
    "    img_arr = np.ma.filled(img_arr, fill_value=0)\n",
    "    # 用0dBz来替换非数值的数据\n",
    "    img_arr = np.clip(img_arr, args.field_value_range[0], args.field_value_range[1])\n",
    "    # 裁剪数值 指定范围之外的数值对应的是与沉降不相关的粒子\n",
    "    # 由于该数值范围落在0-255内 我们即可将之直接视为像素值的大小  \n",
    "    img_arr = img_arr.astype(\"uint8\")\n",
    "    # 从浮点变为整型 否则绘图时候许多库都不支持 参见3.1 同时也减少了数组大小\n",
    "    # 但训练时还要将之转回浮点数 因为模型参数需要是浮点数 以便尽可能精确地拟合标签\n",
    "    # 这步要放到各种处理的最后 尽量减少近似误差\n",
    "    \n",
    "    if_required = check_if_single_img_covers_intense_precip(img_arr)\n",
    "    \n",
    "    return img_arr, if_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:55.963112Z",
     "start_time": "2021-10-30T01:40:55.941772Z"
    },
    "code_folding": [
     0
    ],
    "id": "CY2jBYAFQNpo"
   },
   "outputs": [],
   "source": [
    "def save_image_plots(file_count): # ? 考虑if_remote\n",
    "    \"\"\"\n",
    "    Discription\n",
    "    ---\n",
    "    Extract radar data from numerous sigmet files as 2D arrays, then make transformations\n",
    "    for better plotting and finally save all the plots into different folders \n",
    "    according to their specific dates.\n",
    "    The filenames delibrately designed to include both the time info and the content info,\n",
    "    which means if each image covers intense precipitation content.\n",
    "    \n",
    "    Parameters\n",
    "    ---\n",
    "    file_count : int\n",
    "        The number of radar data files having been downloaded, which indicates\n",
    "        the total amount of plots shold be saved.\n",
    "        It is used for counting how many plots have been saved so far.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for date in args.dates:\n",
    "        #>> 设置并创建用于保存各数组的各文件夹的共同上级目录\n",
    "        if use_colab:\n",
    "            root = \"/content/drive/MyDrive/MyProjects/Weather Nowcasting/XMB-7\"\n",
    "            save_dir = f\"{root}/{args.img_root}/{date}\"\n",
    "            # 注意 现在保存的是已处理过的图像数组 而非原始雷达数据\n",
    "            # 所以此时当然就要指明图像大小 因为图像大小不同图像数组也就不同\n",
    "            # ? 这里其实有修正空间 把if_remote拉进来\n",
    "        else:\n",
    "            save_dir = f\"{args.img_root}/{date}\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        files_dir = f\"{args.file_root}/{date}\"\n",
    "        files = os.listdir(files_dir)\n",
    "        \n",
    "        #>> 按天逐个文件抽取数据 转成图像数组 然后同天的都存储到同一个文件夹里\n",
    "        if os.path.exists(save_dir) and \\\n",
    "        len(files) == len(os.listdir(save_dir)):\n",
    "        # 若该天的数据之前曾经绘图过 则直接计数\n",
    "            count += len(files)\n",
    "            print(f\"{count}/{file_count} data files plotted and saved in groups...\")\n",
    "            \n",
    "        else:\n",
    "        # 若该天的数据之前未曾绘图过 则开始绘图并将之保存\n",
    "            for file in files:\n",
    "                file_path = os.path.join(files_dir, file)\n",
    "                radar_data = pyart.io.read(file_path).extract_sweeps([0]) \n",
    "                # 只提取首次扫描水平面的数据 减少读取的数据量\n",
    "                img_arr, if_required = get_single_image_array_with_precip_flag(radar_data)\n",
    "                precip_sign = args.precip_sign if if_required else \"\"\n",
    "                save_path = f\"{save_dir}/{file[4: -4]}{precip_sign}.png\" \\\n",
    "                if len(file) == 23 \\\n",
    "                else f\"{save_dir}/{file[4: -8]}{precip_sign}.png\"\n",
    "                # 以时间点为名来保存图像\n",
    "                # 原始雷达文件名共有两种 一种长度为23 一种长度为27\n",
    "                # 同时还以沉降标志为名来保存图像 从而为稍后数据集的构建提供方便\n",
    "                img = Image.fromarray(img_arr)\n",
    "                # 如前所述 经处理的雷达数据的二维数组天然就是一幅黑白图像\n",
    "                img.save(save_path)\n",
    "                count += 1\n",
    "                print(f\"{count}/{file_count} data files plotted and saved in groups...\")\n",
    "                  \n",
    "    print()\n",
    "    print(\"Saving plots all finished.\")\n",
    "    print()\n",
    "    \n",
    "    # ? 这里其实完全可以把后续处理一并做了 毕竟都做了循环了\n",
    "    # ? 亦即不绘图存图了 就直接照着雷达文件来构造Dataset实例和Dataloader实例 在前者中组装序列 在后者中读取图像\n",
    "    # ? 但应该需要挺长时间 所以这里还是选择分开\n",
    "    # ? 再者对新手也更友好 毕竟可以看到雷达图像的样子\n",
    "    # ? 但理论上整个过程其实完全可以封装成一个类 比如就叫DataConstructor 直接用来生成三个数据集\n",
    "    # ? 可以尝试一下 看看只读取数组但不保存图像的代码运行时间如何 \n",
    "    # ? 如果每次训练都在生成dataloader那里大量消耗时间 就还不如把绘图存图分离出来先行做完 后续就不必重复了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:55.982572Z",
     "start_time": "2021-10-30T01:40:55.966208Z"
    },
    "code_folding": [
     0
    ],
    "id": "ZllRtpfpQNpo"
   },
   "outputs": [],
   "source": [
    "def get_improper_dates():\n",
    "    \"\"\"\n",
    "    Discription\n",
    "    ---\n",
    "    Check wihch dates have enough images (args.thresholds[\"sequence\"]) \n",
    "    with the precipitation flag \"_P\" in their filenames. \n",
    "    \n",
    "    Reutrns\n",
    "    ---\n",
    "    imp_dates : list\n",
    "        A list of dates that aren't desired for training.\n",
    "    imp_ratio : float\n",
    "        The ratio that the desired dates accouts for. \n",
    "        I think it would be better for training when exceeding 70%. \n",
    "    \"\"\"\n",
    "    imp_dates = []\n",
    "    for date in args.dates: \n",
    "        count = 0\n",
    "        img_dir = os.path.join(args.img_root, date)\n",
    "        imgs = os.listdir(img_dir)\n",
    "        for img in imgs:\n",
    "            if args.precip_sign in img:\n",
    "                count += 1\n",
    "        \n",
    "        if count < args.thresholds[\"sequence\"]:\n",
    "            imp_dates.append(date)\n",
    "            \n",
    "        imp_ratio = len(imp_dates) / len(args.dates)\n",
    "        \n",
    "    return imp_dates, imp_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7mgL4u6QNpo"
   },
   "source": [
    "# Construct Datasets of Image Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "B2v-XOulQNpq"
   },
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:56.002427Z",
     "start_time": "2021-10-30T01:40:55.984319Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "id": "2yXa9oYPQNpq"
   },
   "outputs": [],
   "source": [
    "# ? 如前所述 该部分或许会把上面的函数都囊括进来封装成一个类 比如DataConstructor\n",
    "# ? 具体有待试验 但是感觉会很耗时 反而得不偿失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:56.021760Z",
     "start_time": "2021-10-30T01:40:56.004209Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "id": "yqHzzcCOQNpq"
   },
   "outputs": [],
   "source": [
    "# 提取图像数组 排成序列 构造训练集验证集和测试集 滤除训练集中沉降强度过低的序列\n",
    "# 对一个图像序列中的每个图片都做一个平均池化 \n",
    "# 如果某一卷积结果里面有x个数值超过了阈值 那么对应的那一张图像就会被算作沉降强度较高\n",
    "# 而一个图像序列中只要包含了y个沉降强度较高的图像 那么该图像序列作为一个整体就会被算作沉降强度较高\n",
    "# 同时还要提取图像序列的时间信息序列 一方面用于绘图 另一方面用于训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:40:56.040251Z",
     "start_time": "2021-10-30T01:40:56.023585Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "id": "1t6h95MgQNpq"
   },
   "outputs": [],
   "source": [
    "# ? 数据增广可以做 但只能以序列为单位进行数据增广 时间信息不变\n",
    "# ? 索性干脆别做了 反正数据充足"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "v9BybRGFQNpq"
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:36:23.903107Z",
     "start_time": "2021-11-01T02:36:22.663652Z"
    },
    "hidden": true,
    "id": "seRSRHqlQNps",
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwJ76amqQNps"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.213067Z",
     "start_time": "2021-10-30T01:41:10.209982Z"
    },
    "code_folding": [],
    "id": "cPCvDaUyQNps",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# def check_if_seq_covers_intense_precip(path_seq):\n",
    "#     \"\"\"\n",
    "#     Description\n",
    "#     ---\n",
    "#     Given a sequence of image names, extract the intense precipitation info\n",
    "#     and count how many images are with the '_P' flag. \n",
    "#     If exceeds the given threshold, considered this sequence as required for training.\n",
    "    \n",
    "#     Parameters\n",
    "#     ---\n",
    "#     path_seq : list\n",
    "#         A single sequence of image paths.\n",
    "    \n",
    "#     Returns\n",
    "#     ---\n",
    "#     if_required : bool\n",
    "#         A flag to indicate if a image sequence is required for training.\n",
    "#     \"\"\"\n",
    "#     assert args.thresholds[\"sequence\"] <= len(path_seq), \"Not adequate frames in a sequence.\"\n",
    "#     # ? 有看到文章说不宜多用assert 不如用if...else...来控制\n",
    "    \n",
    "#     count = 0\n",
    "#     for path in path_seq:\n",
    "#         if args.precip_sign in path[-6:]:\n",
    "#         # 这般检测\"_P\"只出现一次\n",
    "#         # 避免路径里面还含有\"_P\" \n",
    "#             count += 1\n",
    "            \n",
    "#     if count >= args.thresholds[\"sequence\"]:\n",
    "#         if_required = True\n",
    "#     else:\n",
    "#         if_required = False\n",
    "        \n",
    "#     return if_required\n",
    "\n",
    "# # 如前所述 这个函数未必要用 因为想让机器学到沉降形成和消弭的过程\n",
    "# # 所以只筛选强沉降发生的日期即可 只要该天之中有一张图像是强沉降的 那么全天的数据就都用来学习\n",
    "# # 但也把握一下分寸 也别所有天数都只有几张图像是强沉降的 所以也要适当对强沉降天数做一个简单的筛选\n",
    "# # ? 突然想到 这里是不是应该要把数据做一下加权 在提取数组那里进行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.234413Z",
     "start_time": "2021-10-30T01:41:10.214842Z"
    },
    "code_folding": [
     0
    ],
    "id": "YqZmdSr8QNps"
   },
   "outputs": [],
   "source": [
    "# def get_time_difference(img_time, pre_img_time):\n",
    "#     \"\"\"\n",
    "#     Discription\n",
    "#     ---\n",
    "#     Get time difference in seconds between two contineous iamges in a sequence.\n",
    "    \n",
    "#     Parameters\n",
    "#     ---\n",
    "#     img_time, pre_img_time : datetime instance\n",
    "#         The time info of an image as a datetime instance in a sequence.\n",
    "#     pre_img_time : datetime instance\n",
    "#         The time info of the previous one as a datetime instance in the same sequence.\n",
    "#     \"\"\"\n",
    "#     time_delta = img_time - pre_img_time\n",
    "#     # time difference in seconds\n",
    "#     time_delta_in_seconds = datetime.timedelta(time_delta.days, time_delta.seconds).total_seconds() \n",
    "#     # correction for negative numbers\n",
    "    \n",
    "#     return time_delta_in_seconds\n",
    "\n",
    "# # 这个算时间差暂时没用上 先来看看引入绝对时间的效果 但效果很可能不如引入时间差 因为模型复杂度包括数据复杂度不足以支撑预测绝对时间\n",
    "# # 然后再考虑引入相对时间也即时间差\n",
    "# # 但即便引入的是绝对时间 这个函数也能在画图的时候用上 无非就是放到哪一部分而已"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.253648Z",
     "start_time": "2021-10-30T01:41:10.236222Z"
    },
    "code_folding": [
     0
    ],
    "id": "-RFqYIN-QNps",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# def collate_function(data):\n",
    "#     \"\"\"\n",
    "#     :data: a list for a batch of samples. [[string, tensor], ..., [string, tensor]]\n",
    "#     \"\"\"\n",
    "#     transposed_data = list(zip(*data))\n",
    "#     directorys, imgs = transposed_data[0], transposed_data[1]\n",
    "#     imgs = torch.stack(imgs, 0)\n",
    "#     return directorys, imgs\n",
    "\n",
    "# # ? 暂时可以不予关心 我把datetime实例转化为浮点型时间戳了 \n",
    "# # ? 如果直接使用前者 应该就需要该函数了 否则dataloader在生成批量时会出问题 不能预读取\n",
    "# # ? https://blog.csdn.net/liekkas_javey/article/details/87359648\n",
    "# # ? https://blog.csdn.net/weixin_43590796/article/details/119663585\n",
    "\n",
    "# dataloader = torch.utils.data.DataLoader(\n",
    "#     Dataset(transforms=data_transforms, train=False),\n",
    "#     batch_size=2, collate_fn=collate_function, shuffle=True, \n",
    "#     num_workers=1, pin_memory=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.273421Z",
     "start_time": "2021-10-30T01:41:10.255447Z"
    },
    "code_folding": [],
    "id": "zhHCq9KFQNpu",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def get_dataloaders():  \n",
    "    tr_dataset = MyDataset(mode=\"train\")\n",
    "    vl_dataset = MyDataset(mode=\"validation\")\n",
    "    tt_dataset = MyDataset(mode=\"test\")\n",
    "    \n",
    "    tr_dataloader = DataLoader(\n",
    "        tr_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        # ? 如果出错 可以尝试把该语句注释掉 \n",
    "        # ? 这个或许是由Dataset的__getitem__返回如字符串等非数值对象被Dataloader生成了批量所致 \n",
    "        # ? 此时可能就得定义上面介绍的那个collate_function函数\n",
    "        drop_last=True\n",
    "        # 最后一批可能不满 算误差时比较麻烦 \n",
    "        # 索性直接去掉 反正数据够多\n",
    "    )  \n",
    "    vl_dataloader = DataLoader(\n",
    "        vl_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        drop_last=True\n",
    "    )\n",
    "    tt_dataloader = DataLoader(\n",
    "        tt_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    return tr_dataloader, vl_dataloader, tt_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SContWnBQNpu"
   },
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.295773Z",
     "start_time": "2021-10-30T01:41:10.275262Z"
    },
    "code_folding": [],
    "id": "Uk1PMRMOQNpu"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, mode=\"train\"):\n",
    "        assert mode in (\"train\", \"validation\", \"test\"), \\\n",
    "        \"Only support 'train', 'validation' and 'test' for dataset construction.\"\n",
    "        # ? 有看到文章说不宜多用assert 不如用if...else...来控制\n",
    "        \n",
    "        self.path_seqs = []\n",
    "        # 这是图像序列所对应的路径序列 \n",
    "        # 稍后在__getitem__里照着路径序列真正拿到图像序列\n",
    "        \n",
    "        #>> 根据日期比例大致划分训练集和验证集\n",
    "        #>> 这里验证集要和训练集在时间上完全错开才行 \n",
    "        #>> 否则验证集中的部分样本序列很可能会和训练集中的部分样本序列过于相像\n",
    "        sep_idx = int((len(args.dates) - 1) * args.part_ratio)\n",
    "        # 这里不能用整除 因为除数是浮点数 会导致结果也为浮点数\n",
    "        # 而浮点数无法作为索引\n",
    "        assert sep_idx >= 1, \\\n",
    "        \"Inadequate date amount to creat a validation dateset.\"\n",
    "        # ? 有看到文章说不宜多用assert 不如用if...else...来控制\n",
    "        \n",
    "        if mode == \"test\":\n",
    "            dates = args.dates[-1:] \n",
    "            # 最后一天的数据用作测试集\n",
    "        elif mode == \"validation\":\n",
    "            dates = args.dates[sep_idx: -1]\n",
    "            # 其余天数按比例分为训练集和测试集\n",
    "        else:\n",
    "            dates = args.dates[: sep_idx]\n",
    "            \n",
    "        for date in dates: \n",
    "            img_dir = os.path.join(args.img_root, date)\n",
    "            imgs = os.listdir(img_dir)\n",
    "            img_paths = [os.path.join(img_dir, img) for img in imgs]\n",
    "            img_paths.sort()\n",
    "            # 这个排序必须要有 否则图片之间是时间不连续的\n",
    "            \n",
    "            for i in range(len(img_paths) - args.n_seq + 1):\n",
    "                path_seq = img_paths[i: i + args.n_seq]\n",
    "                self.path_seqs.append(path_seq)\n",
    "                \n",
    "#                 # --- \n",
    "#                 # 如前所述 这个函数未必要用 因为想让机器学到沉降形成和消弭的过程\n",
    "#                 # 所以只筛选强沉降发生的日期即可 只要该天之中有一张图像是强沉降的 那么全天的数据就都用来学习\n",
    "#                 # 但要把握一下分寸 也别所有天数都只有几张图像是强沉降的 所以也要适当对强沉降天数做一个简单的筛选\n",
    "#                 if mode == \"train\" \\\n",
    "#                 and check_if_seq_covers_intense_precip(path_seq):\n",
    "#                 # 只有训练集需要去除沉降强度较低的序列 验证集和测试集则不必\n",
    "#                     self.path_seqs.pop()\n",
    "#                 # ---\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #>> 用来存储图像序列所对应的空间信息和时间信息\n",
    "        seq = {}\n",
    "        seq[\"data\"], seq[\"labels\"] = [], []\n",
    "        # 存储图像序列的数据\n",
    "        seq[\"time_stamps\"] = []\n",
    "        # 存储图像序列的时间\n",
    "        \n",
    "        for i in range(args.n_seq):\n",
    "            img_path = self.path_seqs[index][i]\n",
    "            img = Image.open(img_path)\n",
    "            img = np.asarray(img)\n",
    "            if i < args.n_inputs:\n",
    "                seq[\"data\"].append(img)\n",
    "            else:\n",
    "                seq[\"labels\"].append(img)\n",
    "            \n",
    "            img_time = os.path.basename(img_path)[: 15]\n",
    "            img_time = datetime.datetime.strptime(img_time, \"%Y%m%d_%H%M%S\")\n",
    "            img_time = time.mktime(img_time.timetuple())\n",
    "            # 将datetime实例转化为浮点数的时间戳 这样方便构建dataloader实例\n",
    "            # 稍后画图时候再将之转化回来就好\n",
    "            seq[\"time_stamps\"].append(img_time)\n",
    "            \n",
    "        seq[\"data\"] = np.asarray(seq[\"data\"])\n",
    "        seq[\"labels\"] = np.asarray(seq[\"labels\"])\n",
    "        seq[\"time_stamps\"] = np.asarray(seq[\"time_stamps\"])\n",
    "        \n",
    "        return seq\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5NZP4WZQNpu"
   },
   "source": [
    "# Construct Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKoEnsEGQNpx"
   },
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.315767Z",
     "start_time": "2021-10-30T01:41:10.297522Z"
    },
    "code_folding": [],
    "id": "Qa6lXHtEQNpx"
   },
   "outputs": [],
   "source": [
    "# ? 构建多种模型 然后选择其中一种进行训练\n",
    "# ? 暂时只做了ConvLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9ILURnzQNpx"
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T06:02:08.778758Z",
     "start_time": "2021-10-30T11:52:49.819Z"
    },
    "id": "77Zg6nRDQNpx"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wC992-ZkQNpx"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7qRWNATQNpz"
   },
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.356344Z",
     "start_time": "2021-10-30T01:41:10.337348Z"
    },
    "code_folding": [
     0
    ],
    "id": "PxIz5Mq1QNpz"
   },
   "outputs": [],
   "source": [
    "class GRUCell(nn.Module): # ??? 这个到底是怎么从零写出来的 里面这些参数都是怎么设计的\n",
    "    def __init__(self, shape, input_channel, filter_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._shape = shape\n",
    "        self._input_channel = input_channel\n",
    "        self._filter_size = filter_size\n",
    "        self._hidden_size = hidden_size\n",
    "        self._conv = nn.Conv2d(\n",
    "            in_channels=self._input_channel + self._hidden_size, \n",
    "            # hidden state has similar spational struture as inputs \n",
    "            # we simply concatenate them on the feature dimension\n",
    "            out_channels=self._hidden_size * 3, \n",
    "            kernel_size=self._filter_size,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        _hidden, _cell = state\n",
    "        cat_x = torch.cat([x, _hidden], dim=1) \n",
    "        Conv_x = self._conv(cat_x)\n",
    "\n",
    "        r, z, h_cand = torch.chunk(Conv_x, 3, dim=1)\n",
    "\n",
    "        r = func.sigmoid(r)\n",
    "        z = func.sigmoid(z)\n",
    "        h = _cell * f + (1 - z) * func.tanh(h_cand)\n",
    "        o = func.sigmoid(o)\n",
    "        hidden = o * func.tanh(cell)\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.377790Z",
     "start_time": "2021-10-30T01:41:10.358132Z"
    },
    "code_folding": [
     0
    ],
    "id": "VCs1o4WyQNpz"
   },
   "outputs": [],
   "source": [
    "class ConvLSTMCell(nn.Module): # ??? 这个到底是怎么从零写出来的 里面这些参数都是怎么设计的\n",
    "    def __init__(self, shape, input_channel, filter_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._shape = shape\n",
    "        self._input_channel = input_channel\n",
    "        self._filter_size = filter_size\n",
    "        self._hidden_size = hidden_size\n",
    "        self._conv = nn.Conv2d(\n",
    "            in_channels=self._input_channel + self._hidden_size, \n",
    "            # hidden state has similar spational struture as inputs \n",
    "            # we simply concatenate them on the feature dimension\n",
    "            out_channels=self._hidden_size * 4, \n",
    "            # lstm has four gates\n",
    "            kernel_size=self._filter_size,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        _hidden, _cell = state\n",
    "        cat_x = torch.cat([x, _hidden], dim=1) \n",
    "        Conv_x = self._conv(cat_x)\n",
    "\n",
    "        i, f, o, j = torch.chunk(Conv_x, 4, dim=1)\n",
    "\n",
    "        i = func.sigmoid(i)\n",
    "        f = func.sigmoid(f)\n",
    "        cell = _cell * f + i * func.tanh(j)\n",
    "        o = func.sigmoid(o)\n",
    "        hidden = o * func.tanh(cell)\n",
    "\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.410814Z",
     "start_time": "2021-10-30T01:41:10.379728Z"
    },
    "code_folding": [
     0
    ],
    "id": "d_HblLnjQNpz"
   },
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module): # ??? 这个到底是怎么从零写出来的 里面这些参数都是怎么设计的\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #>> declare some parameters that might be used \n",
    "        self.conv_pad = 0\n",
    "        self.conv_kernel_size = 3\n",
    "        self.conv_stride = 1\n",
    "        self.pool_pad = 0\n",
    "        self.pool_kernel_size = 3\n",
    "        self.pool_stride = 3\n",
    "        self.hidden_size = 64\n",
    "        self.size = int(\n",
    "            (args.img_size[0] + 2 * self.conv_pad - (self.conv_kernel_size - 1) - 1) \\\n",
    "            / self.conv_stride + 1\n",
    "        )\n",
    "        self.size1 = int(\n",
    "            (self.size + 2 * self.pool_pad - (self.pool_kernel_size - 1) - 1) \\\n",
    "            /self.pool_stride + 1\n",
    "        )\n",
    "        \n",
    "        #>> define layers\n",
    "        self.conv = nn.Conv2d(\n",
    "             in_channels=1,\n",
    "             out_channels=8,\n",
    "             kernel_size=3,\n",
    "             stride=1,\n",
    "             padding=0\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3)\n",
    "        self.convlstm1 = ConvLSTMCell(\n",
    "            shape=[self.size1, self.size1], \n",
    "            input_channel=8, \n",
    "            filter_size=3,\n",
    "            hidden_size=self.hidden_size\n",
    "        )\n",
    "        self.convlstm2 = ConvLSTMCell(\n",
    "            shape=[self.size1, self.size1], \n",
    "            input_channel=self.hidden_size, \n",
    "            filter_size=3,\n",
    "            hidden_size=self.hidden_size\n",
    "        )\n",
    "        self.deconv = nn.ConvTranspose2d(\n",
    "            in_channels=self.hidden_size, \n",
    "            out_channels=1, \n",
    "            kernel_size=4, \n",
    "            # 对256*256图像是6 对128*128图像是4\n",
    "            stride=3,\n",
    "            padding=0, \n",
    "            output_padding=1\n",
    "        )\n",
    "        self.relu = func.relu\n",
    "\n",
    "#     def forward(self, X, time_stamps): ###\n",
    "#         X_chunked = torch.chunk(X, args.n_inputs, dim=1)\n",
    "#         time_diffs_chunked = torch.chunk(time_diffs, args.n_seq + args.n_inputs, dim=1) ###\n",
    "#         X = None\n",
    "#         output = [None] * (args.n_seq)\n",
    "# #         output = [None] * (args.n_seq + args.n_outputs) ###\n",
    "#         state_size = [args.batch_size, self.hidden_size] + [self.size1, self.size1]\n",
    "#         hidden1 = Variable(torch.zeros(state_size)).cuda()\n",
    "#         cell1 = Variable(torch.zeros(state_size)).cuda()\n",
    "#         hidden2 = Variable(torch.zeros(state_size)).cuda()\n",
    "#         cell2 = Variable(torch.zeros(state_size)).cuda()\n",
    "        \n",
    "#         for i in range(args.n_inputs):                                  \n",
    "#             output[i] = self.conv(X_chunked[i])     \n",
    "#             output[i] = self.pool(output[i])\n",
    "#             hidden1, cell1 = self.convlstm1(output[i],(hidden1,cell1))\n",
    "#             hidden2, cell2 = self.convlstm2(hidden1,(hidden2,cell2))\n",
    "#             output[i] = self.deconv(hidden2)\n",
    "# #             for j in range(args.batch_size): ###\n",
    "# #                 output[i][j] += time_diffs_chunked[i].squeeze()[j]\n",
    "#             output[i] = self.relu(output[i])\n",
    "        \n",
    "#         for i in range(args.n_inputs, args.n_seq):\n",
    "# #         for i in range(args.n_inputs, args.n_seq + args.n_outputs): ###                                               \n",
    "#             output[i] = self.conv(output[i-1])    \n",
    "#             output[i] = self.pool(output[i])\n",
    "#             hidden1, cell1 = self.convlstm1(output[i],(hidden1,cell1))\n",
    "#             hidden2, cell2 = self.convlstm2(hidden1,(hidden2,cell2))\n",
    "#             output[i] = self.deconv(hidden2)\n",
    "# #             for j in range(args.batch_size): ###\n",
    "# #                 output[i][j] += time_diffs_chunked[i].squeeze()[j]\n",
    "#             output[i] = self.relu(output[i])\n",
    "            \n",
    "#         return output[args.n_inputs:]\n",
    "\n",
    "    def forward(self, X):\n",
    "        # ? 关于时间插入在哪 按理来说应该插入在解码器那里 但问题是处理时间要不要和空间分开 放在反卷积的后面 做全连接层\n",
    "        X_chunked = torch.chunk(X, args.n_inputs, dim=1)\n",
    "        # ? 这里为什么要拆 直接遍历第二个维度不行吗 比如 X[:, i, ...]\n",
    "        # ? 稍后试一下二者是否等价 毕竟第一种做法拆完应该还需要合上\n",
    "        X = None\n",
    "        # ? 这个应该是在释放内存 \n",
    "        # ? 那直接del X不就可以了吗\n",
    "        output = [None] * args.n_seq\n",
    "        # 首先生成关于输出的白板 然后再往里挨个填值\n",
    "        state_size = [args.batch_size, self.hidden_size] + [self.size1, self.size1]\n",
    "        hidden1 = Variable(torch.zeros(state_size)).cuda()\n",
    "        cell1 = Variable(torch.zeros(state_size)).cuda()\n",
    "        hidden2 = Variable(torch.zeros(state_size)).cuda()\n",
    "        cell2 = Variable(torch.zeros(state_size)).cuda()\n",
    "#         ### ---\n",
    "#         hidden3 = Variable(torch.zeros(state_size)).cuda()\n",
    "#         cell3 = Variable(torch.zeros(state_size)).cuda()\n",
    "#         hidden4 = Variable(torch.zeros(state_size)).cuda()\n",
    "#         cell4 = Variable(torch.zeros(state_size)).cuda()\n",
    "#         ### ---\n",
    "\n",
    "        for i in range(args.n_inputs):\n",
    "            output[i] = self.conv(X_chunked[i])     \n",
    "            output[i] = self.pool(output[i])\n",
    "            hidden1, cell1 = self.convlstm1(output[i],(hidden1,cell1))\n",
    "            hidden2, cell2 = self.convlstm2(hidden1,(hidden2,cell2))\n",
    "#             #---\n",
    "#             hidden3, cell3 = self.convlstm3(hidden2,(hidden3,cell3))\n",
    "#             hidden4, cell4 = self.convlstm4(hidden3,(hidden4,cell4))\n",
    "#             output[i] = self.deconv(hidden4)\n",
    "#             #---\n",
    "            output[i] = self.deconv(hidden2)\n",
    "            output[i] = self.relu(output[i])\n",
    "\n",
    "        for i in range(args.n_inputs, args.n_seq):                                                 \n",
    "            output[i] = self.conv(output[i-1])    \n",
    "            output[i] = self.pool(output[i])\n",
    "            hidden1, cell1 = self.convlstm1(output[i],(hidden1, cell1))\n",
    "            hidden2, cell2 = self.convlstm2(hidden1,(hidden2, cell2))\n",
    "#             #---\n",
    "#             hidden3, cell3 = self.convlstm3(hidden2,(hidden3, cell3))\n",
    "#             hidden4, cell4 = self.convlstm4(hidden3,(hidden4, cell4))\n",
    "#             output[i] = self.deconv(hidden4)\n",
    "#             #---\n",
    "            output[i] = self.deconv(hidden2)\n",
    "            output[i] = self.relu(output[i])\n",
    "\n",
    "        output = torch.cat(output[args.n_inputs:], dim=1)\n",
    "        # 输入那里把第二维拆开分着算的输出 所以最后还得把这些输出的第二维给合回去\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNVSAtayQNp1"
   },
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jN_iMB7pQNp1"
   },
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NKrHlIXQNp1"
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T05:57:10.225337Z",
     "start_time": "2021-10-30T11:41:40.868Z"
    },
    "id": "jxPeDTYEQNp1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "from torch_ssim import ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtNVlnRxQNp3"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.460214Z",
     "start_time": "2021-10-30T01:41:10.456623Z"
    },
    "code_folding": [],
    "id": "Gt04tPerQNp3"
   },
   "outputs": [],
   "source": [
    "def get_devices():\n",
    "    devices = [\n",
    "        torch.device(f\"cuda:{i}\") for i in range(torch.cuda.device_count())\n",
    "    ]\n",
    "    devices = devices if devices else [torch.device(\"cpu\")]\n",
    "    torch.backends.cudnn.benchmark = True  \n",
    "    # automatically detect best algorithm for the running machine\n",
    "    # ? 这个对CPU也好使吗 应该不会 毕竟有了cudnn\n",
    "    # ? 找时间安了pytorch试试\n",
    "    return devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.480094Z",
     "start_time": "2021-10-30T01:41:10.461891Z"
    },
    "code_folding": [],
    "id": "a4xilRwZQNp3"
   },
   "outputs": [],
   "source": [
    "### ? reload=True的分支还没写完 \n",
    "### ? 先用reload=False把这一分支跳过 正常是默认reload=True的\n",
    "def get_model(archi=\"ConvLSTM\", reload=False):\n",
    "    assert archi in (\"ConvLSTM\", \"ConvGRU\"), \\\n",
    "    f\"Class {archi} is not defined.\"\n",
    "    \n",
    "    if reload:\n",
    "        print(\"Reloading the latset model to resume previous training\",\n",
    "              \"or reloading the best previously trained model to make predictions.\",\n",
    "              sep=\" \")\n",
    "        model = torch.load(args.model_save_path)\n",
    "        # ? 试了 直接读进来的model没有[epoch]等等数据\n",
    "#         checkpoint = torch.load(args.checkpoint_save_path)\n",
    "#         start_epoch = checkpoint[\"epoch\"]\n",
    "#         best_accuracy = checkpoint[\"best_accuracy\"]\n",
    "#         model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "#         print(f\"Have loaded checkpoint '{args.checkpoint_save_path}' (trained for {checkpoint[\"epoch\"]} epochs)\"\n",
    "    \n",
    "    else:\n",
    "        print(f\"Initiating a new model of {archi}...\")\n",
    "        model = eval(archi)()\n",
    "        # 对某一个类进行实例化\n",
    "        # 比如eval(\"ConvLSTM\")()=ConvLSTM()\n",
    "    \n",
    "    devices = get_devices()\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "    # 考虑多卡并行\n",
    "        model = nn.DataParallel(model, device_ids=devices)\n",
    "    else:\n",
    "        model = model.to(devices) # 这里或许应该写成devices[0]\n",
    "\n",
    "    return model, devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.499842Z",
     "start_time": "2021-10-30T01:41:10.481882Z"
    },
    "code_folding": [
     1
    ],
    "id": "PzF70P7WQNp3"
   },
   "outputs": [],
   "source": [
    "### ? 这段代码还没开始改 这是用于读取之前checkpoint参数\n",
    "def _get_params(params_name):\n",
    "    '''\n",
    "    params_name: 'params_name'\n",
    "    '''\n",
    "    exec(\"from {m}.{s} import {f}\".format(m='.models.params', s=params_name,  f='params'), globals())\n",
    "    return params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.519315Z",
     "start_time": "2021-10-30T01:41:10.501588Z"
    },
    "code_folding": [
     14
    ],
    "id": "U2W49-O8QNp3"
   },
   "outputs": [],
   "source": [
    "def MAE():\n",
    "    return nn.L1Loss()\n",
    "    # ? 这里有待深究 总之没()不行\n",
    "    # ? https://blog.csdn.net/m13526413031/article/details/116426016\n",
    "\n",
    "def MSE():\n",
    "    return nn.MSELoss()\n",
    "\n",
    "def Smooth_MAE():\n",
    "    return nn.smooth_l1_loss\n",
    "\n",
    "# def LogCosh(output, target):\n",
    "#     return torch.mean(torch.log(torch.cosh(output - target))) \n",
    "\n",
    "def get_loss_fx(loss_type=\"MSE\"):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ---\n",
    "    loss_type : str\n",
    "        Indicating which evaluation metric is used for training.\n",
    "    \"\"\"\n",
    "    assert loss_type in args.criterion\n",
    "    \n",
    "    loss_fx = eval(loss_type)\n",
    "\n",
    "    return loss_fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.539107Z",
     "start_time": "2021-10-30T01:41:10.520926Z"
    },
    "code_folding": [],
    "id": "VQ77I68IQNp3"
   },
   "outputs": [],
   "source": [
    "# def ssim(\n",
    "#     X, Y, data_range=255, \n",
    "#     size_average=True, \n",
    "#     win_size=11, win_sigma=1.5, win=None, \n",
    "#     K=(0.01, 0.03), \n",
    "#     nonnegative_ssim=False\n",
    "# ):\n",
    "#     r\"\"\" interface of ssim\n",
    "#     Args:\n",
    "#         X (torch.Tensor): a batch of images, (N,C,H,W)\n",
    "#         Y (torch.Tensor): a batch of images, (N,C,H,W)\n",
    "#         data_range (float or int, optional): value range of input images. (usually 1.0 or 255)\n",
    "#         size_average (bool, optional): if size_average=True, ssim of all images will be averaged as a scalar\n",
    "#         win_size: (int, optional): the size of gauss kernel\n",
    "#         win_sigma: (float, optional): sigma of normal distribution\n",
    "#         win (torch.Tensor, optional): 1-D gauss kernel. if None, a new kernel will be created according to win_size and win_sigma\n",
    "#         K (list or tuple, optional): scalar constants (K1, K2). Try a larger K2 constant (e.g. 0.4) if you get a negative or NaN results.\n",
    "#         nonnegative_ssim (bool, optional): force the ssim response to be nonnegative with relu\n",
    "#     Returns:\n",
    "#         torch.Tensor: ssim results\n",
    "#     \"\"\"\n",
    "\n",
    "#     if len(X.shape) != 4:\n",
    "#         raise ValueError('Input images should be 4-d tensors.')\n",
    "#     # ! 使用这个替代assert\n",
    "\n",
    "#     if not X.type() == Y.type():\n",
    "#         raise ValueError('Input images should have the same dtype.')\n",
    "\n",
    "#     if not X.shape == Y.shape:\n",
    "#         raise ValueError('Input images should have the same shape.')\n",
    "    \n",
    "#     if win is not None: # set win_size\n",
    "#         win_size = win.shape[-1]\n",
    "\n",
    "#     if not (win_size % 2 == 1):\n",
    "#         raise ValueError('Window size should be odd.')\n",
    "    \n",
    "#     if win is None:\n",
    "#         win = _fspecial_gauss_1d(win_size, win_sigma)\n",
    "#         win = win.repeat(X.shape[1], 1, 1, 1)\n",
    "    \n",
    "#     ssim_per_channel, cs = _ssim(X, Y,\n",
    "#                                 data_range=data_range,\n",
    "#                                 win=win,\n",
    "#                                 size_average=False,\n",
    "#                                 K=K)\n",
    "#     if nonnegative_ssim:\n",
    "#         ssim_per_channel = torch.relu(ssim_per_channel)\n",
    "    \n",
    "#     if size_average:\n",
    "#         return ssim_per_channel.mean()\n",
    "#     else:\n",
    "#         return ssim_per_channel.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.558773Z",
     "start_time": "2021-10-30T01:41:10.540892Z"
    },
    "id": "XM8PGzdNQNp6"
   },
   "outputs": [],
   "source": [
    "def SSIM(output, target):\n",
    "    '''\n",
    "    Input:\n",
    "        should be 5D (samples, channels, frames, heigth, width).\n",
    "    Return:\n",
    "        the structural similarity between two matrices. \n",
    "        (using only first dimension of channels, so it should have 1 channel to make it work)\n",
    "    '''\n",
    "#     return ssim(output[:,0,...], target[:,0,...], size_average=1, data_range=1)\n",
    "    return ssim(output, target, size_average=1, data_range=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.579067Z",
     "start_time": "2021-10-30T01:41:10.560591Z"
    },
    "code_folding": [
     0
    ],
    "id": "2Y6aM09CQNp6"
   },
   "outputs": [],
   "source": [
    "def get_optimizer():\n",
    "    optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, beta2), eps=eps, weight_decay=weight_decay)\n",
    "    LR_step_size = int(max_epochs / lr_steps)\n",
    "    gamma = 0.7\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=LR_step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.600149Z",
     "start_time": "2021-10-30T01:41:10.580869Z"
    },
    "code_folding": [],
    "id": "gP0a7E_aQNp6"
   },
   "outputs": [],
   "source": [
    "def get_pred_loss(vl_dataloader, model, criterion, device, plot_preds=False):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    ssim = 0 ###\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for n_batch, batch_data in enumerate(vl_dataloader):\n",
    "        # 提取第几批次只是为了计算批量平均误差\n",
    "#             X, Y, init_times, time_diffs = batch_data\n",
    "            X = batch_data[\"data\"].float().to(device)\n",
    "            Y = batch_data[\"labels\"].float().to(device)\n",
    "            # 图像数据的数据类型必须匹配网络参数的数据类型 所以要把uint8转为float32\n",
    "#             output = model(X, time_diffs)\n",
    "            output = model(X)\n",
    "    \n",
    "            ### 新加的:\n",
    "#             label_list = [img for i, img in enumerate(output_list) if i % 2 == 0] \n",
    "#             label_list = torch.cat(label_list, dim=1)\n",
    "#             loss = criterion(label_list, Y)\n",
    "            loss += criterion(output, Y)\n",
    "            # 训练时候 类似SGD 我们是单批量优化参数 而验证时候则是整个验证集\n",
    "            ssim += SSIM(output, Y) ###\n",
    "#             for i in range(args.n_outputs):\n",
    "#                 loss += criterion(pred_list[i].squeeze(), Y[:, i, :, :])\n",
    "#                 # pred_list是(5, 10, 1, 256, 256) \n",
    "#                 # Y是(10, 5, 256, 256)\n",
    "\n",
    "        loss /= (n_batch * args.batch_size * args.n_outputs)\n",
    "        ssim /= (n_batch * args.batch_size * args.n_outputs)\n",
    "        \n",
    "    return loss, ssim ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.619570Z",
     "start_time": "2021-10-30T01:41:10.601968Z"
    },
    "code_folding": [],
    "id": "UsP9U1XKQNp6"
   },
   "outputs": [],
   "source": [
    "# ### ? \n",
    "# def train(taining_dataset, validation_dataset, model_name, loss_name, params_module=None, save_dir=None):\n",
    "\n",
    "#     # params can be retrieve from explicit full path, or model name\n",
    "#     if params_module is None:\n",
    "#         params_module = model_name\n",
    "        \n",
    "#     if not _is_path(taining_dataset): # if not path (just filename) use default location\n",
    "#         taining_dataset = '../data/datasets/'+ taining_dataset.replace('.npy','') + '.npy'\n",
    "#     if not _is_path(validation_dataset): # if not path (just filename) use default location\n",
    "#         validation_dataset = '../data/datasets/'+ validation_dataset.replace('.npy','') + '.npy'\n",
    "                                              \n",
    "#     # import all files                                                         \n",
    "#     params       = _get_params(params_module)\n",
    "#     get_model    = _get_model_fx(model_name)    \n",
    "#     get_loss_fx  = _get_loss_fx(loss_name)\n",
    "\n",
    "#     model = Torch_Trainer(taining_dataset, validation_dataset, get_model, get_loss_fx)\n",
    "#     model.train(params)\n",
    "#     model.save_checkpoint(path=save_dir)\n",
    "#     print(\"Training finished\")\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.639054Z",
     "start_time": "2021-10-30T01:41:10.621411Z"
    },
    "code_folding": [
     0
    ],
    "id": "-dMtpfOuQNp8",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# def save_checkpoint(epoch, state_dict(), ):\n",
    "#     \"\"\"\n",
    "#     Discription\n",
    "#     ---\n",
    "#     Save the best model having been trained so far.\n",
    "    \n",
    "#     Todo\n",
    "#     ---\n",
    "#     As shown in *pag. 39, stopping training when validation loss is at the minimum should be the best possible checkpoint. \n",
    "#     So, implement stopping when validation loss starts increasing (use histeresis to missinterpretate noise as minimum)\n",
    "#     You can comment/uncomment the 3 saving in the fx as what suits you best. They are just to reproduce results.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     if path==None:\n",
    "#         base_dir = str(Path(__file__).parent.parent.parent)\n",
    "#         data_dir = \"/data/checkpoints/\"\n",
    "#         path = base_dir + data_dir\n",
    "\n",
    "#     state = {\n",
    "#         \"epoch\": epoch + 1,\n",
    "#         \"state_dict\": state_dict(),\n",
    "#         \"best_accuracy\": vl_loss}\n",
    "#     torch.save(state, path + self.save_filename)\n",
    "\n",
    "#     try:\n",
    "#         torch.save(self.best_model_loss, path + \"bestLOSS_\" + self.save_filename)\n",
    "#         #torch.save(self.best_model_ssim, path + \"bestSSIM_\" + self.save_filename)\n",
    "#     except:\n",
    "#         pass\n",
    "#     filename = self.params[\"save_filename\"].replace(\"pth\",\"param\")\n",
    "#     with open(path + filename,\"wb\") as my_file_obj:\n",
    "#             pickle.dump(self.params, my_file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.658146Z",
     "start_time": "2021-10-30T01:41:10.640932Z"
    },
    "code_folding": [
     0
    ],
    "id": "s4pPeGZMQNp8"
   },
   "outputs": [],
   "source": [
    "# def load_checkpoint(self, params, ckpoint_path=None , cuda=True, verbose=True):\n",
    "#     '''\n",
    "#     Load a checkpoint, to make predictions or to resume training.\n",
    "#     Inputs:\n",
    "#         params: see Class help\n",
    "#         ckpoint_path: checkpoint path. \n",
    "#             If not given it looks for the checkpoint in mlnowcasting/data/checkpoints/ with the name of the params['save_filename']\n",
    "#         cuda: if True try to uses GPU\n",
    "#         verbose: print information\n",
    "#     '''\n",
    "#     if not self.model:\n",
    "#         self.model = self.get_model(params['n_filter'], params['dropout']).float()\n",
    "\n",
    "#     if not ckpoint_path:\n",
    "#         base_dir = str(Path(__file__).parent.parent.parent)\n",
    "#         data_dir = '/data/checkpoints/'\n",
    "#         path = base_dir + data_dir\n",
    "#         ckpoint_path = path + params['save_filename']\n",
    "\n",
    "#     use_gpu = torch.cuda.is_available()\n",
    "#     if cuda and use_gpu:\n",
    "#         self.model.cuda()\n",
    "#         checkpoint = torch.load(ckpoint_path)\n",
    "#     else:\n",
    "#         checkpoint = torch.load(ckpoint_path, map_location=torch.device('cpu') )\n",
    "\n",
    "#     self.model.eval()\n",
    "#     start_epoch = checkpoint['epoch']\n",
    "#     best_accuracy = checkpoint['best_accuracy']\n",
    "#     self.model.load_state_dict(checkpoint['state_dict'])\n",
    "#     if verbose:\n",
    "#         print(\"=> loaded checkpoint '{}' (trained for {} epochs)\".format(params['save_filename'], checkpoint['epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:10.685740Z",
     "start_time": "2021-10-30T01:41:10.660092Z"
    },
    "code_folding": [],
    "id": "TW_qAw83QNp8"
   },
   "outputs": [],
   "source": [
    "def run_training(reload=False):\n",
    "    learning_rates = []\n",
    "\n",
    "    loss_values = {\"train\": [], \"validation\": []}\n",
    "    vl_ssim_values = []\n",
    "#     lrs = []\n",
    "    best_vl_loss = 1000\n",
    "    best_vl_ssim = 0\n",
    "    \n",
    "    model, device = get_model(archi=\"ConvLSTM\")\n",
    "    model.train()\n",
    "    \n",
    "    tr_dataloader, vl_dataloader, _ = get_dataloaders()\n",
    "    criterion = get_loss_fx(\"MSE\")()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=args.lr,weight_decay=args.wd)\n",
    "    # 这里有待完善\n",
    "    \n",
    "    for epoch in range(args.n_epoches):\n",
    "        elapsed = 0\n",
    "        t = time.time()\n",
    "        \n",
    "        print(\"---\")\n",
    "        \n",
    "        for n_batch, batch_data in enumerate(tr_dataloader):\n",
    "            loss = 0\n",
    "            # 如前所述 训练时候需要效仿SGD单批量优化参数 而验证时候则是整个验证集\n",
    "            \n",
    "            X = Variable(batch_data[\"data\"].float()).to(device)\n",
    "            Y = Variable(batch_data[\"labels\"].float()).to(device)\n",
    "            optimizer.zero_grad()   \n",
    "            output = model(X)\n",
    "#             ### 新加的\n",
    "#             label_list = [img for i, img in enumerate(output_list) if i % 2 == 0] \n",
    "#             label_list = torch.cat(label_list, dim=1)\n",
    "#             loss = criterion(label_list, Y)\n",
    "\n",
    "            loss = criterion(output, Y)\n",
    "            # https://blog.csdn.net/m13526413031/article/details/116426016\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if n_batch != 0 and n_batch % 100 == 0:\n",
    "                elapsed += (time.time() - t)\n",
    "                t = time.time()\n",
    "                \n",
    "                tr_avg_loss = loss / (args.batch_size * args.n_outputs)\n",
    "                loss_values[\"train\"].append(tr_avg_loss)\n",
    "                \n",
    "                vl_avg_loss, vl_avg_ssim = get_pred_loss(vl_dataloader=vl_dataloader, model=model, device=device, criterion=criterion)\n",
    "                loss_values[\"validation\"].append(vl_avg_loss)\n",
    "                vl_ssim_values.append(vl_avg_ssim)\n",
    "                \n",
    "                if vl_avg_loss < best_vl_loss:\n",
    "                    best_vl_loss = vl_avg_loss\n",
    "                    state_dict = copy.deepcopy(model.state_dict())\n",
    "                    torch.save(model, f\"model_{epoch + 1}.pkl\") ###\n",
    "                    best_model_loss = {\"epoch\": epoch + 1, \"state_dict\": state_dict, \"best_loss\": best_vl_loss}\n",
    "                    \n",
    "                if vl_avg_ssim > best_vl_ssim:\n",
    "                    best_vl_ssim = vl_avg_ssim\n",
    "                    state_dict = copy.deepcopy(model.state_dict())\n",
    "                    best_model_ssim = {\"epoch\": epoch + 1, \"state_dict\": state_dict, \"best_loss\": best_vl_ssim} \n",
    "                \n",
    "                print(f\"Epoch: {epoch}, Iteration: {n_batch}, Tr_Avg_Loss: {tr_avg_loss:.6f}, Vl_Avg_Loss: {vl_avg_loss:.6f}, Vl_Avg_SSIM: {vl_avg_ssim:.6f}\")\n",
    "                \n",
    "        print(\"Finished an epoch...\")\n",
    "        print(f\"Elapsed seconds from last epoch: {elapsed:.2f}\")\n",
    "        \n",
    "#         torch.save(model, \"model_{0}.pkl\".format(epoch)) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qw5tITPZQNp8"
   },
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T15:21:48.600761Z",
     "start_time": "2021-10-29T15:21:28.462199Z"
    },
    "id": "NJfialNbQNp-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:52.960334Z",
     "start_time": "2021-10-30T01:41:52.953703Z"
    },
    "id": "7YbdFQb8QNp-"
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.io import img_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:53.421630Z",
     "start_time": "2021-10-30T01:41:53.415308Z"
    },
    "code_folding": [],
    "id": "rcgjU5zOQNp-"
   },
   "outputs": [],
   "source": [
    "def get_color_map():\n",
    "    \"\"\"\n",
    "    Discription\n",
    "    ---\n",
    "    Customize a color map used for plotting reflectivity values.\n",
    "    \"\"\"\n",
    "    colors = [(255, 255, 255), (164, 140, 177), (83, 2, 125), (49, 0, 199), (0, 0, 255), \n",
    "              (5, 101, 134), (10, 182, 18), (105, 170, 18), (255, 255, 0), (255, 213, 0), \n",
    "              (253, 169, 2), (255, 84, 0), (255, 0, 0)]  \n",
    "    # R -> G -> B\n",
    "    colors = [[each / 255 for each in color] for color in colors]\n",
    "    # 列表没有广播机制 所以无法直接除一个数\n",
    "    cmap_name = \"darts\"\n",
    "    return LinearSegmentedColormap.from_list(cmap_name, colors, N=13)\n",
    "    # ? 这个N=13啥意思?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:45:27.127006Z",
     "start_time": "2021-10-30T01:45:27.117432Z"
    },
    "code_folding": [],
    "id": "9wJub5RGQNp-"
   },
   "outputs": [],
   "source": [
    "def plot_obs_pred(X, Y, N=3, plot_inputs=False):\n",
    "#     if plot_inputs:\n",
    "#         for i in range(args.n_inputs):\n",
    "#             plt.subplot(1, args.n_inputs, i + 1)\n",
    "#             plt.imshow(X[0][i], cmap=cmap)\n",
    "    \n",
    "    model = torch.load(\"model_21.pkl\")\n",
    "    output = model(X.float().cuda())\n",
    "    cmap = get_color_map()\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=N, figsize=(20, 10))\n",
    "    \n",
    "    i = 0\n",
    "    for ax in axes.flat:\n",
    "        if i < args.n_inputs:\n",
    "            img = ax.imshow(Y[0][i], vmin=0, vmax=70, cmap=cmap)\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_xticklabels([])\n",
    "#             ax.axis(\"off\")\n",
    "            i += 1\n",
    "        \n",
    "        else:\n",
    "            img = ax.imshow(output[0][i - args.n_inputs].squeeze().detach().cpu(), vmin=0, vmax=70, cmap=cmap)\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_xticklabels([])\n",
    "#             ax.axis(\"off\")\n",
    "    \n",
    "    axes[0,0].set_ylabel(\"OBS\")\n",
    "    axes[1,0].set_ylabel(\"PRED\")\n",
    "    \n",
    "    cbar = fig.colorbar(img, ax=axes.ravel().tolist(), location=\"bottom\", aspect=100)\n",
    "    cbar.set_label(\"dbZ\", rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:41:55.006215Z",
     "start_time": "2021-10-30T01:41:54.995522Z"
    },
    "code_folding": [],
    "id": "cRyulAzmQNp-"
   },
   "outputs": [],
   "source": [
    "def plot_obs_pred(target, prediction, N=3, cmap='darts', title_files=None):\n",
    "    '''\n",
    "    Simple plotting of some frames of the target and prediction on a figure with two rows, one for each.\n",
    "    N: how many frames of each to plot\n",
    "    cmap: colormap. Recommended to use 'darts' or 'binary'.\n",
    "    title_files: list of each frame original file to use as titles.\n",
    "    '''\n",
    "    # define cmap and ranges\n",
    "    if cmap == 'darts':\n",
    "        cmap = get_cmap()\n",
    "\n",
    "    max_ = np.max(target)\n",
    "    vmax = 1\n",
    "    if max_ > 2:\n",
    "        vmax = 70\n",
    "    elif max_ > 70:\n",
    "        vmax = 255\n",
    "    else:\n",
    "        vmax = 1\n",
    "        \n",
    "    n_frames = target.shape[0]\n",
    "    skip = int(n_frames/N) # how many frames to skip to plot only N frames\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=N, figsize=(15,8))\n",
    "    i = 0\n",
    "    plot_sequence = target # auxiliary variable to use for plotting\n",
    "    for ax in axes.flat:\n",
    "        # once the target has been plotted, switch to prediction\n",
    "        if i == N:\n",
    "            plot_sequence = prediction\n",
    "            i = 0\n",
    "        im = ax.imshow(plot_sequence[i*skip,...],vmin=0, vmax=vmax, cmap=cmap)\n",
    "        if title_files is not None:\n",
    "            ax.set_title(get_title(title_files, i*skip))\n",
    "        #ax.axis('off')\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "        i += 1\n",
    "        \n",
    "    axes[0,0].set_ylabel('OBS')\n",
    "    axes[1,0].set_ylabel('PRED')\n",
    "    # show the colorbar at the bottom horizontally\n",
    "    cbar = fig.colorbar(im, ax=axes.ravel().tolist(), location='bottom', aspect=100)\n",
    "    cbar.set_label('dbZ', rotation=0)\n",
    "    fig.show()\n",
    "    plt.show()\n",
    "    #fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:44:07.689119Z",
     "start_time": "2021-10-30T01:42:01.482580Z"
    },
    "id": "8K9GBMYcQNqA"
   },
   "outputs": [],
   "source": [
    "_, _, tt_dataloader = get_dataloaders()\n",
    "for n_batch, b_data in enumerate(tt_dataloader):\n",
    "    X = b_data[\"data\"]\n",
    "    Y = b_data[\"labels\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:44:09.177600Z",
     "start_time": "2021-10-30T01:44:07.904839Z"
    },
    "id": "al8q8yFSQNqA"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "for i in range(args.n_inputs):\n",
    "    plt.subplot(1, args.n_inputs, i + 1)\n",
    "    plt.imshow(X[0][i], cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:44:58.180545Z",
     "start_time": "2021-10-30T01:44:58.042297Z"
    },
    "id": "czlo3HVYQNqD"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "for i in range(args.n_inputs):\n",
    "    plt.subplot(1, args.n_inputs, i + 1)\n",
    "    plt.imshow(X[0][i], vmin=0, vmax=70, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T01:45:32.171112Z",
     "start_time": "2021-10-30T01:45:31.603388Z"
    },
    "id": "oPCUFbp2QNqD"
   },
   "outputs": [],
   "source": [
    "plot_obs_pred(X, Y, N=3, plot_inputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ib9CR55QNqD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [
    "5od_pdQRE4lj"
   ],
   "name": "1 - 10.28.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "50bc9c60ce257d1ba4c12a89132d94e2f513c873f6d1178cba979650034b40ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
